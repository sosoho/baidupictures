# baidupictures
和同学想做一个图片分类的小项目，需要在百度图片上抓取一百多个关键词对应的图片各500张，在参考例程的基础上中加入了从txt文件中逐行读取关键词和将图片按类别保存在不同文件夹下的功能，但其中多线程部分暂未实现。\<br> 
首先查看网页源码，发现同一张图片有四种网址：thumbURL、middleURL、hoverURL、objURL，其中前三种都有反爬虫措施，于是选择第四种，该网址为图片的原网址。\<br> 
由于百度图片为异步加载形式，更多的图片在下拉时加载而不是翻页形式，因此需要在chrome或者Firefox中查看页面元素，下拉页面滚动条，分析XHR的变化，找到所需的json数据。在链接中，rn 参数指的是一页包含的图片数量，最多60。 pn 指得是第多少张  word 指的是搜索的关键字，还有其它的一些无关紧要的参数。\<br> 
参考http://blog.csdn.net/hbuxiaoshe/article/details/44780653 的解密方法对json数据进行解密。\<br> 
爬虫的流程为：\<br> 
    生成网址列表\<br> 
    发送HTTP请求获取json数据\<br> 
    解析数据得到网址\<br> 
    下载\<br> 
